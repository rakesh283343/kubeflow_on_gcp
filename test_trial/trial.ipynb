"""
@author: shreya Verma
"""
from kfp import compiler
import kfp.dsl as dsl
import kfp.gcp as gcp
import kfp.notebook
import sys
import json

class ObjectDict(dict):
  def __getattr__(self, name):
    if name in self:
      return self[name]
    else:
      raise AttributeError("No such attribute: " + name)


@dsl.pipeline(
  name='Basic KubeFlow Pipeline',
  description='Feature Eng,Training,Testing & Deployment'
)
def ftreng_train_test_and_deploy(
        project='cohesive-gadget-166410',
        bucket_uri='gs://social_network-kubeflow-on-mnist/Social_Network_Ads.csv',
        region='us-central1',
        test_size=0.3,
        file_name='',
        target_var='Purchased',
        model_bucket_name='rf-vj-model',
        model_name='rf-vj',
        framework='scikit-learn',
        version_key_word='rf_model_'
        
        ):
# Step 1: create training dataset using Apache Beam on Cloud Dataflow
    feature_eng = dsl.ContainerOp(
            name='feature_eng',
            # image needs to be a compile-time string
            image='us.gcr.io/kubeflow-on-mnist/feature_eng',
            arguments=[
                    '--path',bucket_uri,
                    '--filename',file_name,
                    '--t_size',test_size
                    ]
            #,file_outputs={'bucket': '/output.txt'}
            ).apply(gcp.use_gcp_secret('user-gcp-sa'))

# Step 2: Train the model and find best set of hyperparameter.
    train = dsl.ContainerOp(
            name='train',
            # image needs to be a compile-time string
            image='us.gcr.io/kubeflow-on-mnist/train',
            arguments=[
                    '--path',bucket_uri,
                    '--target',target_var
                       ]
            #,file_outputs={'jobname': '/output.txt'}
            ).apply(gcp.use_gcp_secret('user-gcp-sa'))
    train.after(feature_eng)
    test = dsl.ContainerOp(
            name='test',
            # image needs to be a compile-time string
            image='us.gcr.io/kubeflow-on-mnist/test',
            arguments=[
                '--path',bucket_uri,
                '--target',target_var
                      ]
            ).apply(gcp.use_gcp_secret('user-gcp-sa'))
    test.after(train)
    cm = dsl.ContainerOp(
            name='cm',
            image='us.gcr.io/kubeflow-on-mnist/cm',
            arguments=[],
            file_outputs={
                'MLPipeline UI metadata': '/mlpipeline-ui-metadata.json',
                'MLPipeline UI metadata': '/mlpipeline-metrics.json'
            }
            ).apply(gcp.use_gcp_secret('user-gcp-sa'))
    cm.after(test)
	
	filename='trial.zip'
    compiler.Compiler().compile(ftreng_train_test_and_deploy,filename)